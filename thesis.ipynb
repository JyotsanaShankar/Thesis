{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JyotsanaShankar/Thesis/blob/main/thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "723VNTwJ80R1"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqijSLRU51Lm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae35cde-bc30-4816-9141-f85918fa317a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Collecting farm-haystack[all]\n",
            "  Downloading farm_haystack-1.21.0-py3-none-any.whl (816 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.9/816.9 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Collecting boilerpy3 (from farm-haystack[all])\n",
            "  Downloading boilerpy3-1.0.6-py3-none-any.whl (22 kB)\n",
            "Collecting events (from farm-haystack[all])\n",
            "  Downloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[all]) (4.19.0)\n",
            "Collecting lazy-imports==0.3.1 (from farm-haystack[all])\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[all]) (10.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[all]) (1.5.3)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack[all]) (3.10.0)\n",
            "Collecting posthog (from farm-haystack[all])\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Collecting prompthub-py==4.0.0 (from farm-haystack[all])\n",
            "  Downloading prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[all]) (1.10.12)\n",
            "Collecting quantulum3 (from farm-haystack[all])\n",
            "  Downloading quantulum3-0.9.0-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank-bm25 (from farm-haystack[all])\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting requests-cache<1.0.0 (from farm-haystack[all])\n",
            "  Downloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.3.0 (from farm-haystack[all])\n",
            "  Downloading scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sseclient-py (from farm-haystack[all])\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[all]) (8.2.3)\n",
            "Collecting tiktoken>=0.5.1 (from farm-haystack[all])\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[all]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[all]) (23.1.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack[all])\n",
            "  Downloading cattrs-23.1.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack[all])\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[all]) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[all]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[all]) (3.2.0)\n",
            "Collecting azure-ai-formrecognizer>=3.2.0b2 (from farm-haystack[all])\n",
            "  Downloading azure_ai_formrecognizer-3.3.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[all]) (4.11.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from farm-haystack[all]) (3.4.4)\n",
            "Collecting python-docx (from farm-haystack[all])\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-frontmatter (from farm-haystack[all])\n",
            "  Downloading python_frontmatter-1.0.0-py3-none-any.whl (9.0 kB)\n",
            "Collecting python-magic (from farm-haystack[all])\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Collecting tika (from farm-haystack[all])\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mlflow (from farm-haystack[all])\n",
            "  Downloading mlflow-2.7.1-py3-none-any.whl (18.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<2.8.0,>=2.0.15 (from farm-haystack[all])\n",
            "  Downloading rapidfuzz-2.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from farm-haystack[all])\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiorwlock<2,>=1.3.0 (from farm-haystack[all])\n",
            "  Downloading aiorwlock-1.3.0-py3-none-any.whl (10.0 kB)\n",
            "Collecting ray[serve]<2,>=1.9.1 (from farm-haystack[all])\n",
            "  Downloading ray-1.13.0-cp310-cp310-manylinux2014_x86_64.whl (54.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting selenium>=4.11.0 (from farm-haystack[all])\n",
            "  Downloading selenium-4.13.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3 (from farm-haystack[all])\n",
            "  Downloading boto3-1.28.57-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore>=1.27 (from farm-haystack[all])\n",
            "  Downloading botocore-1.31.57-py3-none-any.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers>=2.2.0 (from farm-haystack[all])\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langdetect (from farm-haystack[all])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from farm-haystack[all]) (3.8.1)\n",
            "Collecting openai-whisper (from farm-haystack[all])\n",
            "  Downloading openai-whisper-20230918.tar.gz (794 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image>1.14 (from farm-haystack[all])\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Collecting pytesseract>0.3.7 (from farm-haystack[all])\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting pymupdf>=1.18.16 (from farm-haystack[all])\n",
            "  Downloading PyMuPDF-1.23.4-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting canals==0.8.0 (from farm-haystack[all])\n",
            "  Downloading canals-0.8.0-py3-none-any.whl (33 kB)\n",
            "Collecting openai (from farm-haystack[all])\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beir (from farm-haystack[all])\n",
            "  Downloading beir-2.0.0.tar.gz (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime (from farm-haystack[all])\n",
            "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime-tools (from farm-haystack[all])\n",
            "  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers) (3.20.3)\n",
            "Collecting accelerate>=0.20.3 (from transformers)\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[all]) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[all]) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[all]) (0.10.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[all]) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[all]) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->farm-haystack[all])\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->farm-haystack[all])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[all]) (7.0.0)\n",
            "Collecting num2words (from quantulum3->farm-haystack[all])\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting azure-core<2.0.0,>=1.23.0 (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all])\n",
            "  Downloading azure_core-1.29.4-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msrest>=0.6.21 (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all])\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-common~=1.1 (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all])\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore>=1.27->farm-haystack[all])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[all]) (1.1.3)\n",
            "Collecting PyMuPDFb==1.23.3 (from pymupdf>=1.18.16->farm-haystack[all])\n",
            "  Downloading PyMuPDFb-1.23.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jarowinkler<2.0.0,>=1.2.0 (from rapidfuzz<2.8.0,>=2.0.15->farm-haystack[all])\n",
            "  Downloading jarowinkler-1.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click<=8.0.4,>=7.0 (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<=1.43.0,>=1.28.1 (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading grpcio-1.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[serve]<2,>=1.9.1->farm-haystack[all]) (1.0.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[serve]<2,>=1.9.1->farm-haystack[all]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[serve]<2,>=1.9.1->farm-haystack[all]) (1.4.0)\n",
            "Collecting virtualenv (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading virtualenv-20.24.5-py3-none-any.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading starlette-0.31.1-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorful (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1 (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading gpustat-1.1.1.tar.gz (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prometheus-client<0.14.0,>=0.7.1 (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading opencensus-0.11.3-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[serve]<2,>=1.9.1->farm-haystack[all]) (6.4.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[serve]<2,>=1.9.1->farm-haystack[all]) (3.8.5)\n",
            "Collecting py-spy>=0.2.0 (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn==0.16.0 (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading uvicorn-0.16.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp-cors (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting asgiref>=3.4.0 (from uvicorn==0.16.0->ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Collecting h11>=0.8 (from uvicorn==0.16.0->ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio~=0.17 (from selenium>=4.11.0->farm-haystack[all])\n",
            "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium>=4.11.0->farm-haystack[all])\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->farm-haystack[all]) (2.5)\n",
            "Collecting pytrec_eval (from beir->farm-haystack[all])\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting faiss_cpu (from beir->farm-haystack[all])\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elasticsearch==7.9.1 (from beir->farm-haystack[all])\n",
            "  Downloading elasticsearch-7.9.1-py2.py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from beir->farm-haystack[all])\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.8.0,>=0.7.0 (from boto3->farm-haystack[all])\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Downloading weaviate_client-3.24.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opensearch-py>=2 (from farm-haystack[all])\n",
            "  Downloading opensearch_py-2.3.1-py2.py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[all]) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow->farm-haystack[all])\n",
            "  Downloading databricks-cli-0.17.8.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[all]) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow->farm-haystack[all])\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[all]) (6.8.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[all]) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow->farm-haystack[all])\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow->farm-haystack[all])\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<3 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[all]) (2.2.5)\n",
            "Collecting querystring-parser<2 (from mlflow->farm-haystack[all])\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[all]) (2.0.20)\n",
            "Requirement already satisfied: pyarrow<14,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[all]) (9.0.0)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[all]) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow->farm-haystack[all])\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack[all])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coloredlogs (from onnxruntime->farm-haystack[all])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->farm-haystack[all]) (23.5.26)\n",
            "Collecting onnx (from onnxruntime-tools->farm-haystack[all])\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from onnxruntime-tools->farm-haystack[all]) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from onnxruntime-tools->farm-haystack[all]) (9.0.0)\n",
            "Collecting py3nvml (from onnxruntime-tools->farm-haystack[all])\n",
            "  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper->farm-haystack[all]) (0.56.4)\n",
            "INFO: pip is looking at multiple versions of openai-whisper to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openai-whisper (from farm-haystack[all])\n",
            "  Downloading openai-whisper-20230314.tar.gz (792 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.9/792.9 kB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading openai-whisper-20230308.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ffmpeg-python==0.2.0 (from openai-whisper->farm-haystack[all])\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper->farm-haystack[all]) (0.18.3)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx->farm-haystack[all]) (4.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->farm-haystack[all]) (67.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[serve]<2,>=1.9.1->farm-haystack[all]) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[serve]<2,>=1.9.1->farm-haystack[all]) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[serve]<2,>=1.9.1->farm-haystack[all]) (1.9.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow->farm-haystack[all])\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions (from torch)\n",
            "  Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[all]) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[all]) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[all]) (0.9.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow->farm-haystack[all]) (1.6.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow->farm-haystack[all]) (2.3.7)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow->farm-haystack[all]) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow->farm-haystack[all])\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-ml-py>=11.450.129 (from gpustat>=1.0.0b1->ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading nvidia_ml_py-12.535.108-py3-none-any.whl (36 kB)\n",
            "Collecting blessed>=1.17.1 (from gpustat>=1.0.0b1->ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow->farm-haystack[all]) (3.16.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (3.1.1)\n",
            "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all])\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (1.3.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->farm-haystack[all]) (2.0.2)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium>=4.11.0->farm-haystack[all]) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium>=4.11.0->farm-haystack[all])\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium>=4.11.0->farm-haystack[all]) (1.3.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium>=4.11.0->farm-haystack[all])\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "INFO: pip is looking at multiple versions of urllib3[socks] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting urllib3[socks]<3,>=1.26 (from selenium>=4.11.0->farm-haystack[all])\n",
            "  Downloading urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.2/123.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3<3,>=1.21.1->requests->transformers) (1.7.1)\n",
            "Collecting validators<1.0.0,>=0.21.2 (from weaviate-client>2->farm-haystack[all])\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client>2->farm-haystack[all])\n",
            "  Downloading Authlib-1.2.1-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->farm-haystack[all])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.8,>=0.3.0 (from datasets->beir->farm-haystack[all])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->beir->farm-haystack[all])\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->beir->farm-haystack[all])\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elastic-transport<8 (from farm-haystack[all])\n",
            "  Downloading elastic_transport-7.16.0-py2.py3-none-any.whl (35 kB)\n",
            "INFO: pip is looking at multiple versions of farm-haystack[elasticsearch7] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting beir (from farm-haystack[all])\n",
            "  Downloading beir-1.0.1.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading beir-1.0.0.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading beir-0.2.3.tar.gz (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elasticsearch (from beir->farm-haystack[all])\n",
            "  Downloading elasticsearch-8.10.0-py3-none-any.whl (414 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.0/415.0 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from beir->farm-haystack[all]) (2.13.0)\n",
            "Collecting tensorflow-text (from beir->farm-haystack[all])\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from beir->farm-haystack[all]) (0.14.0)\n",
            "Collecting elastic-transport<9,>=8 (from elasticsearch->beir->farm-haystack[all])\n",
            "  Downloading elastic_transport-8.4.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elasticsearch (from beir->farm-haystack[all])\n",
            "  Downloading elasticsearch-8.9.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.5/395.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.8.2-py3-none-any.whl (393 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.9/393.9 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.8.1-py3-none-any.whl (393 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.9/393.9 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.8.0-py3-none-any.whl (393 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.8/393.8 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of farm-haystack[elasticsearch7] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading elasticsearch-8.7.0-py3-none-any.whl (387 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.9/387.9 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.6.2-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.4/385.4 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.6.1-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.4/385.4 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.6.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.4/385.4 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.5.3-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.3/385.3 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading elasticsearch-8.5.2-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.3/385.3 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.5.1-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.3/385.3 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.5.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.3/385.3 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.4.3-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.6/384.6 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.4.2-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.6/384.6 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.4.1-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.0/385.0 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.4.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.0/385.0 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.3.3-py3-none-any.whl (382 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.5/382.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.3.2-py3-none-any.whl (382 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.5/382.5 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.3.1-py3-none-any.whl (382 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.5/382.5 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.3.0-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.0/382.0 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.2.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.5/381.5 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.2.2-py3-none-any.whl (378 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.7/378.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.2.1-py3-none-any.whl (378 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.7/378.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.2.0-py3-none-any.whl (378 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.6/378.6 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.1.3-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.2/373.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.1.2-py3-none-any.whl (372 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.8/372.8 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.1.1-py3-none-any.whl (372 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.8/372.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.1.0-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.3/373.3 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.0.1-py3-none-any.whl (372 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.8/372.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-8.0.0-py3-none-any.whl (369 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.7/369.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading elasticsearch-7.17.9-py2.py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.0/386.0 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (2.3.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow>=2.2.0 (from beir->farm-haystack[all])\n",
            "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (0.2.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow>=2.2.0->beir->farm-haystack[all])\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->beir->farm-haystack[all]) (0.33.0)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow>=2.2.0->beir->farm-haystack[all])\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow>=2.2.0->beir->farm-haystack[all])\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.15,>=2.14.0 (from tensorflow>=2.2.0->beir->farm-haystack[all])\n",
            "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of urllib3[socks] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting faiss_cpu (from beir->farm-haystack[all])\n",
            "  Downloading faiss_cpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psycopg2-binary (from farm-haystack[all])\n",
            "  Downloading psycopg2_binary-2.9.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy-utils (from farm-haystack[all])\n",
            "  Downloading SQLAlchemy_Utils-0.41.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy<3,>=1.4.0 (from mlflow->farm-haystack[all])\n",
            "  Downloading SQLAlchemy-1.4.49-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pinecone-client<3,>=2.0.11 (from farm-haystack[all])\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->ray[serve]<2,>=1.9.1->farm-haystack[all]) (3.7.1)\n",
            "Collecting starlette (from ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper->farm-haystack[all]) (0.39.1)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[serve]<2,>=1.9.1->farm-haystack[all])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[serve]<2,>=1.9.1->farm-haystack[all]) (2.11.1)\n",
            "Collecting xmltodict (from py3nvml->onnxruntime-tools->farm-haystack[all])\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting tensorflow>=2.2.0 (from beir->farm-haystack[all])\n",
            "  Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text (from beir->farm-haystack[all])\n",
            "  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow>=2.2.0 (from beir->farm-haystack[all])\n",
            "  Downloading tensorflow-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch torchvision farm-haystack[all]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsBm9syX7sD5"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.13.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqx_MANK9Qao"
      },
      "outputs": [],
      "source": [
        "!pip install tabula-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umlzGSZFNfIe"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2 pycryptodome"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "CmO0Ql46fIIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piS8PfiH84_n"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6IpFXB99Es8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz\n",
        "import tabula\n",
        "import io\n",
        "import PyPDF2\n",
        "import pickle\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICr0k2_g7_Mo"
      },
      "outputs": [],
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "from haystack.nodes import PreProcessor, FARMReader, DensePassageRetriever, DenseRetriever, PDFToTextConverter\n",
        "from haystack.document_stores.faiss import FAISSDocumentStore"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.metrics.scores import f_measure\n",
        "# nltk.download() # Run this if you get error to download punkt. select download adn type 'punkt' and hit enter"
      ],
      "metadata": {
        "id": "SCYND_h6fPCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbIWiAAl9aol"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W4PS_to9dQR"
      },
      "source": [
        "### Pdf File processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ktu5P9RKLB84"
      },
      "source": [
        "Remove header and footer to remove unnecessary duplicate headers, footers and page numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7kNEDWzNvUX"
      },
      "outputs": [],
      "source": [
        "def remove_header_footer(header, footer, input_path, output_path):\n",
        "  with open(input_path,'rb') as pdf_file:\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    pdf_writer = PyPDF2.PdfWriter()\n",
        "\n",
        "    for page in pdf_reader.pages:\n",
        "      page.mediabox.top = page.mediabox.top - header\n",
        "      page.mediabox.bottom = page.mediabox.bottom + footer\n",
        "      pdf_writer.add_page(page)\n",
        "\n",
        "  with open(output_path, 'wb') as output_pdf:\n",
        "    pdf_writer.write(output_pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg1QLXGMLZxj"
      },
      "source": [
        "Funtion to extract text data(using PyMuPdf) and tabular data(using tabula)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNS60bDSnYiO"
      },
      "outputs": [],
      "source": [
        "def get_text_data(pdf_path):\n",
        "  doc = fitz.open(temp_file_path)\n",
        "  pdf_text = \"\"\n",
        "  print('reading', pdf_path, 'having', len(doc), 'pages' )\n",
        "\n",
        "  for page_num in range(len(doc)):\n",
        "      page = doc[page_num]\n",
        "      pdf_text += page.get_text(\"text\")\n",
        "  return pdf_text\n",
        "\n",
        "def get_tabular_data(pdf_path):\n",
        "  # Extract tabular data using tabula-py\n",
        "  try:\n",
        "    tabular_data = tabula.read_pdf(pdf_path, pages=\"all\", format='JSON')\n",
        "  except Exception as e:\n",
        "      tabular_data = []\n",
        "\n",
        "  # Initialize an empty list to store the converted tabular data\n",
        "  tabular_data_dicts = []\n",
        "\n",
        "  cleaned_df = [df.dropna(axis=1, how='all') for df in tabular_data]\n",
        "  # Iterate through the list of DataFrames and convert each one to a list of dictionaries\n",
        "  for df in cleaned_df:\n",
        "      if not df.empty:\n",
        "          tabular_data_dicts.append(df.to_dict(orient='records'))\n",
        "  return tabular_data_dicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGiRuhfAm4JY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538560d7-e17d-45d4-c280-e4f054f434b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "preprocessor = PreProcessor(split_by='word',\n",
        "                            split_length=250,\n",
        "                            split_overlap=50,\n",
        "                            clean_whitespace=True,\n",
        "                            clean_header_footer=True,\n",
        "                            clean_empty_lines=True,\n",
        "                            split_respect_sentence_boundary=True\n",
        "                            )\n",
        "\n",
        "def get_processed_documents(all_documents):\n",
        "  processed_docs = []\n",
        "  for files in all_documents:\n",
        "    processed_docs = processed_docs + preprocessor.process([files])\n",
        "  return processed_docs\n",
        "\n",
        "def get_qa_pipeline(document_store, reader):\n",
        "  retriever = DensePassageRetriever(document_store=document_store, use_gpu=True)\n",
        "  document_store.update_embeddings(retriever)\n",
        "  qa_pipeline = ExtractiveQAPipeline(reader=reader, retriever=retriever)\n",
        "  return qa_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZyYoMVWLyrH"
      },
      "source": [
        "Defining FAISSDocumentStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TLT1IKyoc2i"
      },
      "outputs": [],
      "source": [
        "faiss_doc = 'faiss_document_store.db'\n",
        "if os.path.exists(faiss_doc):\n",
        "          os.remove(faiss_doc)\n",
        "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\", return_embedding=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIZ-D13AnADw"
      },
      "source": [
        "Defining Reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOppp5NBomMX"
      },
      "outputs": [],
      "source": [
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgKrmjBmozME"
      },
      "source": [
        "Defining Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M31YXNjCIioV"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"questions\":[\n",
        "        ['How much is  greenhouse gas (GHG) emission is generated from production during the reporting period?',\n",
        "        'How much is the scope 1 emissions for the reporting period?',\n",
        "        'How much is the scope 2 emission for the reporting period?',\n",
        "        'How much percentage of scope 1 emissions is reduced in the reporting period?',\n",
        "        'By when company is targetting to become carbon neutral?',\n",
        "        'How much water company consume in reporting year?',\n",
        "        'How much waste company generate in reporting year?',\n",
        "        'How much energy is consumed in reporting year?']\n",
        "    ]\n",
        "}\n",
        "\n",
        "questions = data[\"questions\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"ground_truth_real.json\", \"r\") as json_file:\n",
        "    ground_truth = json.load(json_file)"
      ],
      "metadata": {
        "id": "nCgxxbDbo4JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4KtuVIRMP_o"
      },
      "source": [
        "Generating answer for all the files present in **pdf_files** folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzwngV-t7-iG"
      },
      "outputs": [],
      "source": [
        "# Flag to use PDFToTextConverter from Haystack\n",
        "use_pdf_to_text_converter = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygjZyaoQ9ZrE"
      },
      "outputs": [],
      "source": [
        "pdf_dir = \"pdf_files\"\n",
        "temp_pdf_dir = \"temp\"\n",
        "header = 40\n",
        "footer = 40\n",
        "all_pdf_answer = {}\n",
        "\n",
        "# Iterate through PDF files in the directory\n",
        "for pdf_file in os.listdir(pdf_dir):\n",
        "\n",
        "    all_documents = []\n",
        "    if pdf_file.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
        "        temp_file_path = os.path.join(temp_pdf_dir, pdf_file)\n",
        "\n",
        "        # Remove header footer\n",
        "        remove_header_footer(header,\n",
        "                             footer,\n",
        "                             pdf_path,\n",
        "                             temp_file_path)\n",
        "\n",
        "        if use_pdf_to_text_converter:\n",
        "          converter = PDFToTextConverter(remove_numeric_tables=False, valid_languages=['en'])\n",
        "          all_documents = converter.convert(temp_file_path, meta = {\"file_name\": pdf_file})\n",
        "\n",
        "        else:\n",
        "          # Extract text from the PDF file\n",
        "          pdf_text = get_text_data(temp_file_path)\n",
        "\n",
        "          # Extract tabular data\n",
        "          tabular_data_dicts = get_tabular_data(temp_file_path)\n",
        "\n",
        "          # Create a document and add it to the document store\n",
        "          document = {\n",
        "              \"content\": pdf_text,\n",
        "              \"tables\": tabular_data_dicts,\n",
        "              \"meta\": {\"file_name\": pdf_file}\n",
        "          }\n",
        "          all_documents.append(document)\n",
        "\n",
        "        if os.path.exists(temp_file_path):\n",
        "          os.remove(temp_file_path)\n",
        "\n",
        "        processed_docs = get_processed_documents(all_documents)\n",
        "\n",
        "        document_store.delete_documents()\n",
        "        document_store.write_documents(processed_docs)\n",
        "\n",
        "        qa_pipeline = get_qa_pipeline(document_store, reader)\n",
        "\n",
        "        answers = []\n",
        "        #questions = list(ground_truth[pdf_file].keys())\n",
        "        for question in questions:\n",
        "          result = qa_pipeline.run(query=question, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 1}})\n",
        "          print(result)\n",
        "          answers.append(result)\n",
        "\n",
        "        all_pdf_answer[pdf_file] = answers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWffZ5DOVyN2"
      },
      "source": [
        "Save answer in pickle file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hwdqreFVEWV"
      },
      "outputs": [],
      "source": [
        "answer_file_name = 'answers.pkl'\n",
        "\n",
        "with open(answer_file_name, 'wb') as fp:\n",
        "    pickle.dump(all_pdf_answer, fp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvzPZV0GV3U6"
      },
      "source": [
        "Read answer from pickle file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KE5gNjVV6YR"
      },
      "outputs": [],
      "source": [
        "with open(answer_file_name, 'rb') as fp:\n",
        "    answers = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loJ7u6RuwTkO"
      },
      "outputs": [],
      "source": [
        "answer_list = [{'answer': answer.answer, 'score' : answer.score} for answer in answers['1.pdf'][0]['answers']]\n",
        "(answer_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOCAViX1Zy7A"
      },
      "outputs": [],
      "source": [
        "min_ans = {}\n",
        "for pdf_file in os.listdir(pdf_dir):\n",
        "  min_ans_list = []\n",
        "  answer_list = all_pdf_answer[pdf_file]\n",
        "  for answer in answer_list:\n",
        "    min_ans_list.append(\n",
        "      {\n",
        "          \"query\":answer['query'],\n",
        "          \"answers\": [{'answer': answer.answer, 'score' : answer.score} for answer in answer['answers']]\n",
        "      }\n",
        "    )\n",
        "  min_ans[pdf_file] = min_ans_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd3KurIvcZl3"
      },
      "outputs": [],
      "source": [
        "generated_answer = min_ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smlniYc3ckn6"
      },
      "outputs": [],
      "source": [
        "min_answer_file_name = 'min_answers.json'\n",
        "json_data = json.dumps(min_ans)\n",
        "\n",
        "with open(min_answer_file_name, 'w') as fp:\n",
        "    fp.write(json_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPNBbZUhbQeQ"
      },
      "outputs": [],
      "source": [
        "all_pdf_answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzCU4RZcehE-"
      },
      "outputs": [],
      "source": [
        "ground_truth_answers = {\n",
        "    questions[0]: [\"2,062 \", \"10,068\",\"25.922\",\"13.9\",\"11,048,504\",\"7,114,667\",\"13.9\",\"11,509,756\",\"145\",\"106\",\"1.5\", \"0.2\",\"259,429\",\"14,336,42777,3\",\"1,237\"],\n",
        "    questions[1]: [\"1,027\", \"326\",\"742\", \"333\",\"1,471\",\"10,068\",\"11,509,756\", \"106\",\"46\",\"0.4\",\"54\",\"5\",\"1.5\",\"0.2\",\"304\",\"138\"],\n",
        "    questions[2]: [\"1,492\", \"1035\",\"426\", \"954\",\"11,245\",\"147\",\"9,631\", \"135,183\",\"60\",\"39\",\"28\",\"10\",\"206\",\"178\",\"28\",\"10\",\"0.9\",\"1.5\",\"0.2\",\"499\",\"\"],\n",
        "    questions[3]: [\"18\", \"20\", \"25\",\"more than 20\",\"between 30 and 50 percent\",\"28 percent\"],\n",
        "    questions[4]: [\"2025\",\"2039\",\"2040\",\"2050\",\"2030\"],\n",
        "    questions[5]: [\"11,778\",\"113.736\", \"60.8\", \"1.16\",\"1.14\",\"14\"],\n",
        "    questions[6]: [\"1,025\",\"1.183\",\"0.633\",\"25.3\",\"1.14\",\"2,334\",\"126,736\",\"12,702\"],\n",
        "    questions[7]: [\"419.6 GWh\",\"1,005 GWh\",\"86.7 GWh\",\"76.761\",\"0.041\",\"859\",\"836\",\"5\",\"1,632\",\"1,424\",\"1,201\",\"207\",\"625\",\"10\",\"10,883,534\",\"1,326,842\",\"2,126,050\",\"0.2\",\"0.7\",\"14,336,42777.,3\"],\n",
        "\n",
        "  #\"15,136,769 metric tons\", \"145000 metric tonnes \",\" 1.7 metric tones reduced\", \"259,429 metric tonnes \"\n",
        "    #\"Implemented energy-efficient lighting\", \"Switched to electric vehicles\", \"Installed solar panels\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdJD_qc5JtBz"
      },
      "outputs": [],
      "source": [
        "for answerdetail in answers:\n",
        "  print(50*\"-\")\n",
        "  print(\"Query : \", answerdetail[\"query\"])\n",
        "  print(50*\"-\")\n",
        "  for answer in answerdetail[\"answers\"]:\n",
        "    print(\"Answer : \", answer.answer)\n",
        "    print(\"Score : \", answer.score)\n",
        "    print(\"Filename : \", answer.meta[\"file_name\"])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Metrics"
      ],
      "metadata": {
        "id": "lKM-cuGEenuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate F1 score between predicted and ground truth answers\n",
        "def calculate_f1_score(predicted_answer, ground_truth_answer):\n",
        "\n",
        "    predicted_tokens = word_tokenize(predicted_answer.lower())\n",
        "    gt_tokens = word_tokenize(ground_truth_answer.lower())\n",
        "\n",
        "    # Create sets of unique tokens\n",
        "    predicted_set = set(predicted_tokens)\n",
        "    gt_set = set(gt_tokens)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score using nltk's f_measure function\n",
        "    precision = f_measure(predicted_set, gt_set)\n",
        "    recall = f_measure(gt_set, predicted_set)\n",
        "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    return f1"
      ],
      "metadata": {
        "id": "ULoi3cvfe890"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"ground_truth.json\", \"r\") as json_file:\n",
        "    ground_truth = json.load(json_file)\n",
        "\n",
        "with open(\"generated_answer.json\", \"r\") as json_file:\n",
        "    generated_answer = json.load(json_file)"
      ],
      "metadata": {
        "id": "q_8zgcxQfCsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth"
      ],
      "metadata": {
        "id": "xtST7qdk1Coy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each_file in generated_answer:\n",
        "  print('File:', each_file)\n",
        "  accuracy = 0\n",
        "  f1_scores = []\n",
        "  has_ans = 0\n",
        "  qa_list = generated_answer[each_file]\n",
        "  for qa in qa_list:\n",
        "    question = qa['query']\n",
        "    predicted_answer = qa['answers'][0]['answer']\n",
        "    gt_answer = ground_truth[each_file][question]\n",
        "    if gt_answer == \"\":\n",
        "      continue\n",
        "    else:\n",
        "      if predicted_answer == gt_answer:\n",
        "        accuracy += 1\n",
        "      f1_score = calculate_f1_score(predicted_answer, gt_answer)\n",
        "      f1_scores.append(f1_score)\n",
        "      has_ans = has_ans + 1\n",
        "  total_questions = len(qa_list)\n",
        "  accuracy = accuracy / total_questions\n",
        "  average_f1_score = sum(f1_scores) / total_questions\n",
        "  print(f\"Accuracy: {accuracy:.2f}\")\n",
        "  print(f\"Average F1 Score: {average_f1_score:.2f}\")\n",
        "  print('F1 scores:', f1_scores)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8_NoV4OfYxr",
        "outputId": "cbf75d63-8f8a-4b08-f416-c742e1c42eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: 2.pdf\n",
            "Accuracy: 0.00\n",
            "Average F1 Score: 0.17\n",
            "F1 scores: [0, 0, 0, 0, 0.6666666666666666, 0.6666666666666666]\n",
            "\n",
            "\n",
            "File: 1.pdf\n",
            "Accuracy: 0.12\n",
            "Average F1 Score: 0.12\n",
            "F1 scores: [0, 0, 0, 0, 1.0, 0, 0, 0]\n",
            "\n",
            "\n",
            "File: 5.pdf\n",
            "Accuracy: 0.12\n",
            "Average F1 Score: 0.17\n",
            "F1 scores: [0, 0, 0, 1.0, 0.3333333333333333]\n",
            "\n",
            "\n",
            "File: 3.pdf\n",
            "Accuracy: 0.12\n",
            "Average F1 Score: 0.12\n",
            "F1 scores: [0, 0, 0, 1.0, 0]\n",
            "\n",
            "\n",
            "File: 6.pdf\n",
            "Accuracy: 0.38\n",
            "Average F1 Score: 0.38\n",
            "F1 scores: [1.0, 0, 0, 1.0, 0, 0, 1.0]\n",
            "\n",
            "\n",
            "File: 4.pdf\n",
            "Accuracy: 0.12\n",
            "Average F1 Score: 0.23\n",
            "F1 scores: [0, 0, 0.16666666666666666, 1.0, 0.6666666666666666, 0, 0, 0]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}